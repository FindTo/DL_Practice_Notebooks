{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch import nn","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.334672Z","iopub.execute_input":"2025-10-24T09:14:58.335532Z","iopub.status.idle":"2025-10-24T09:14:58.339422Z","shell.execute_reply.started":"2025-10-24T09:14:58.335493Z","shell.execute_reply":"2025-10-24T09:14:58.338465Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"**Write a function called function01.** It should have the following signature:\n\n```def function01(tensor: torch.Tensor, count_over: str) -> torch.Tensor:```\n\nIf count_over is equal to ‘columns’, return the average of the tensor by columns. If it is equal to ‘rows’, return the average by rows. It is guaranteed that the tensor will be a matrix (i.e., it will have dimension 2).","metadata":{}},{"cell_type":"code","source":"def function01(tensor: torch.Tensor, count_over: str) -> torch.Tensor:\n    if count_over == 'columns':\n\n        return tensor.mean(dim=0)\n\n    elif count_over == 'rows':\n\n        return tensor.mean(dim=1)\n\n    else:\n\n        return 0","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.340901Z","iopub.execute_input":"2025-10-24T09:14:58.341148Z","iopub.status.idle":"2025-10-24T09:14:58.358198Z","shell.execute_reply.started":"2025-10-24T09:14:58.341124Z","shell.execute_reply":"2025-10-24T09:14:58.357441Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"function01(tensor = torch.rand(2, 3), count_over = 'columns')","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.359146Z","iopub.execute_input":"2025-10-24T09:14:58.359422Z","iopub.status.idle":"2025-10-24T09:14:58.368424Z","shell.execute_reply.started":"2025-10-24T09:14:58.359383Z","shell.execute_reply":"2025-10-24T09:14:58.367580Z"},"trusted":true},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tensor([0.4536, 0.9042, 0.2470])"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"**Write function02.** The function should take a dataset as input—a tensor matrix of object features. Your function should create a tensor vector with weights (let them be uniformly distributed on the interval from 0 to 1) and return them for further training of linear regression without a free coefficient. Make these weights of type float32, as gradients will need to be calculated for them during training (use requires_grad).\n\nTranslated with DeepL.com (free version)","metadata":{}},{"cell_type":"code","source":"def function02(tensor: torch.Tensor) -> torch.Tensor:\n    \n    return torch.rand(tensor.shape[1], requires_grad=True, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.369507Z","iopub.execute_input":"2025-10-24T09:14:58.369758Z","iopub.status.idle":"2025-10-24T09:14:58.374971Z","shell.execute_reply.started":"2025-10-24T09:14:58.369711Z","shell.execute_reply":"2025-10-24T09:14:58.374128Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"function02(tensor = torch.rand(2, 3))","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.376725Z","iopub.execute_input":"2025-10-24T09:14:58.376985Z","iopub.status.idle":"2025-10-24T09:14:58.385243Z","shell.execute_reply.started":"2025-10-24T09:14:58.376960Z","shell.execute_reply":"2025-10-24T09:14:58.384415Z"},"trusted":true},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor([0.0577, 0.2165, 0.5643], requires_grad=True)"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"**Write the function function03.**** It should accept a tensor matrix with objects and a tensor vector with correct answers. We will solve the regression problem: def function03(x: torch.Tensor, y: torch.Tensor):\n\nCreate weights for linear regression (without a free coefficient) inside the function. You can use the function from the previous step. Use gradient descent to select the optimal weights for the input data (use a step length of about 1e-2). Return a tensor vector with the optimal weights from the function. Your trained weights should give an MSE of less than one on the training sample.","metadata":{}},{"cell_type":"code","source":"def function03(x: torch.Tensor, y: torch.Tensor):\n    \n    mse = 100\n    i = 0\n    w = function02(x) \n    \n    while mse >= 1:\n        \n        i += 1\n\n        ax = torch.matmul(x, w)\n\n        mse = torch.mean((ax - y) ** 2)\n\n        if i < 20 or i % 10 == 0:\n\n            print(f'MSE at step {i + 1}: {mse.item():.5f}')\n\n        mse.backward()\n\n        with torch.no_grad():\n            \n            w -= w.grad * 1e-2\n            \n        w.grad.zero_()\n\n    return w","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.386456Z","iopub.execute_input":"2025-10-24T09:14:58.386780Z","iopub.status.idle":"2025-10-24T09:14:58.394626Z","shell.execute_reply.started":"2025-10-24T09:14:58.386743Z","shell.execute_reply":"2025-10-24T09:14:58.393875Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"n_features = 2   \nn_objects = 300\n\nw_true = torch.randn(n_features)\nX = (torch.rand(n_objects, n_features) - 0.5) * 5\nY = X @ w_true + torch.randn(n_objects) / 2","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.395535Z","iopub.execute_input":"2025-10-24T09:14:58.395774Z","iopub.status.idle":"2025-10-24T09:14:58.404715Z","shell.execute_reply.started":"2025-10-24T09:14:58.395751Z","shell.execute_reply":"2025-10-24T09:14:58.404077Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"function03(X, Y)","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.405647Z","iopub.execute_input":"2025-10-24T09:14:58.405997Z","iopub.status.idle":"2025-10-24T09:14:58.415976Z","shell.execute_reply.started":"2025-10-24T09:14:58.405957Z","shell.execute_reply":"2025-10-24T09:14:58.415105Z"},"trusted":true},"outputs":[{"name":"stdout","text":"MSE at step 2: 0.52499\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"tensor([0.4266, 0.5838], requires_grad=True)"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"**Write function04.** It should accept a tensor matrix with objects and a tensor with correct answers. We will solve a regression problem: def function04(x: torch.Tensor, y: torch.Tensor):\n\nCreate a fully connected layer inside the function, train this fully connected layer on the input data using gradient descent (use a step length of about 1e-2). Return it from the function. Your fully connected layer should give an MSE on the training sample of less than 0.3.","metadata":{}},{"cell_type":"code","source":"def function04(x: torch.Tensor, y: torch.Tensor):\n    \n    mse = 10\n    i = 0\n    \n    layer = nn.Linear(in_features= x.shape[1], out_features=1)\n    \n    while mse >= 0.3:\n        \n        i += 1\n\n        ax = layer(x).ravel()\n\n        mse = torch.mean((ax - y) ** 2)\n\n        if i < 20 or i % 10 == 0:\n\n            print(f'MSE at step {i + 1} {mse.item():.5f}')\n\n        mse.backward()\n\n        with torch.no_grad():\n            \n            layer.weight -= layer.weight.grad * 1e-2\n            layer.bias -= layer.bias.grad * 1e-2\n            \n        layer.zero_grad()\n\n    return layer","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.417025Z","iopub.execute_input":"2025-10-24T09:14:58.417275Z","iopub.status.idle":"2025-10-24T09:14:58.429093Z","shell.execute_reply.started":"2025-10-24T09:14:58.417248Z","shell.execute_reply":"2025-10-24T09:14:58.428285Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"function04(X, Y)","metadata":{"execution":{"iopub.status.busy":"2025-10-24T09:14:58.444644Z","iopub.execute_input":"2025-10-24T09:14:58.445148Z","iopub.status.idle":"2025-10-24T09:14:58.472322Z","shell.execute_reply.started":"2025-10-24T09:14:58.445118Z","shell.execute_reply":"2025-10-24T09:14:58.471496Z"},"trusted":true},"outputs":[{"name":"stdout","text":"MSE at step 2 3.18926\nMSE at step 3 2.94244\nMSE at step 4 2.71668\nMSE at step 5 2.51016\nMSE at step 6 2.32123\nMSE at step 7 2.14836\nMSE at step 8 1.99019\nMSE at step 9 1.84545\nMSE at step 10 1.71297\nMSE at step 11 1.59171\nMSE at step 12 1.48071\nMSE at step 13 1.37908\nMSE at step 14 1.28603\nMSE at step 15 1.20081\nMSE at step 16 1.12275\nMSE at step 17 1.05125\nMSE at step 18 0.98574\nMSE at step 19 0.92571\nMSE at step 20 0.87069\nMSE at step 21 0.82026\nMSE at step 31 0.49673\nMSE at step 41 0.35789\nMSE at step 51 0.29629\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=2, out_features=1, bias=True)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}